{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c11d8c65",
   "metadata": {},
   "source": [
    "# Explicação rápida dos dados (resumo):\n",
    "\n",
    "- Registros: clientes (customer_id) com variáveis demográficas, comportamentais, transacionais, datas, texto e target churn.\n",
    "- Numéricas: age, income (forte skew + outliers), tenure_months, num_transactions, avg_transaction. \n",
    "    - skew se refere a desequilibrios ou distorções na distribuição.\n",
    "    - outliers são valores extremos que podem distorcer análises estatísticas. Em termos gerais, são dados que fogem do padrão esperado.\n",
    "- Categóricas: country, product, device (BR tem peso maior).\n",
    "- Datas: signup_date, last_login — permitem criar recência, idade da conta, frequência.\n",
    "- Texto: review_text (comentários curtos, útil para TF-IDF/embeddings). -> análise de sentimentos, tópicos.\n",
    "- Target: churn (binário, desequilibrado — ~10% base). -> prever abandono.\n",
    "- Problemas artificiais incluídos: missing (income, last_login, review_text), outliers extremos em income/avg_transaction, duplicatas, distribuição enviesada.\n",
    "    - Esses problemas simulam desafios reais em dados de clientes.\n",
    "\n",
    "# Tarefa proposta (prática de feature engineering + baseline):\n",
    "\n",
    "### Objetivo: montar um pipeline reprodutível que faça engenharia de features, treine um modelo simples e reporte métricas.\n",
    "\n",
    "> Passos mínimos (sugestão):\n",
    "\n",
    "1. Exploração\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "> summary estatistico: refere-se a uma análise descritiva dos dados que inclui medidas como média, mediana, desvio padrão, valores mínimos e máximos, entre outros.\n",
    "- usa-se: \n",
    "    - ```df.describe()``` no pandas.\n",
    "\n",
    "> distribuições: refere-se à forma como os dados estão distribuídos para cada variável. \n",
    "- Isso pode incluir:\n",
    "    - histogramas:\n",
    "        - usa-se:\n",
    "            - ````sns.histplot()```` do seaborn, ````plt.hist()```` do matplotlib.\n",
    "    - boxplots:\n",
    "        - usa-se:\n",
    "            - ````sns.boxplot()```` do seaborn, ````plt.boxplot()```` do matplotlib.\n",
    "    - KDE plots (Kernel Density Estimation):\n",
    "        - usa-se:\n",
    "            - ````sns.kdeplot()```` do seaborn.\n",
    "\n",
    "> correlações: medem quanto uma variável se relaciona com outra.\n",
    "    > A matriz de correlação ````df.corr()```` mostra valores entre -1 e 1, indicando a força e direção da relação.\n",
    "- +1: correlação positiva perfeita (ambas crescem juntas)\n",
    "- 1: correlação negativa perfeita (uma cresce, outra diminui)\n",
    "- 0: sem relação linear clara\n",
    "- usa-se:\n",
    "    - ````sns.heatmap()```` do seaborn para visualizar a matriz de correlação.\n",
    "\n",
    "> contagem por categoria: refere-se à contagem de ocorrências para cada categoria em variáveis categóricas.\n",
    "- usa-se:\n",
    "    - ````df['categoria'].value_counts()```` no pandas.\n",
    "\n",
    "> percentuais de nulos: refere-se à proporção de valores ausentes em cada coluna do dataset.\n",
    "- usa-se:\n",
    "    - ````df.isnull().mean() * 100```` no pandas. -> lê-se como \"percentual de valores nulos por coluna\".\n",
    "\n",
    "\n",
    "> checar duplicatas e formato de datas: refere-se à verificação de registros duplicados no dataset e à validação do formato das colunas de data.\n",
    "- importa pois:\n",
    "    - duplicatas podem ganhar peso indevido.\n",
    "    - datas mal formatadas impedem cálculos corretos de recência, idade da conta, etc. \n",
    "        - exemplo: \n",
    "            - “2025/01/02”, “02-01-2025” e “01-02-25” podem representar coisas diferentes dependendo do padrão adotado (americano vs brasileiro).\n",
    "            - converter signup_date/last_login para datetime.\n",
    "- usa-se para duplicatas:\n",
    "\n",
    "    ```python\n",
    "     # para contar duplicatas.\n",
    "    df.duplicated().sum()\n",
    "\n",
    "     # para visualizar duplicatas.\n",
    "    df[df.duplicated()]\n",
    "\n",
    "    # para remover duplicatas.\n",
    "    df.drop_duplicates()\n",
    "\n",
    "    # para remover duplicatas parcialmente\n",
    "    df = df.drop_duplicates(subset=['customer_id', 'signup_date'])\n",
    "    ```\n",
    "\n",
    "- usa-se para datas:\n",
    "    ```python\n",
    "    # Converter coluna de string para datetime\n",
    "    df['data'] = pd.to_datetime(df['data'], errors='coerce', dayfirst=True)\n",
    "    \n",
    "    # Checar valores inválidos (que viraram NaT)\n",
    "    df['data'].isna().sum()\n",
    "    \n",
    "    # Extrair partes úteis da data\n",
    "    df['ano'] = df['data'].dt.year\n",
    "    df['mes'] = df['data'].dt.month\n",
    "    df['dia_semana'] = df['data'].dt.day_name()\n",
    "\n",
    "    # signup_date/last_login\n",
    "    df['signup_date'] = pd.to_datetime(df['signup_date'], errors='coerce', dayfirst=True)\n",
    "    df['last_login'] = pd.to_datetime(df['last_login'], errors='coerce', dayfirst=True)\n",
    "\n",
    "    ```\n",
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "2. Limpeza\n",
    "    - remover duplicatas (total ou parcial por customer_id + signup_date).\n",
    "    - converter signup_date/last_login para datetime.\n",
    "    - criar coluna boolean indicando se last_login é nulo.\n",
    "    - exemplo: \n",
    "    ```python\n",
    "    df['no_login'] = df['last_login'].isna() # isna() retorna True para valores nulos\n",
    "    ```\n",
    "    <br><br>\n",
    "3. Features temporais\n",
    "    > recency = (today - last_login).days (usar um referência fixa para reprodutibilidade).\n",
    "    - Conceito: Mede a quantidade de dias que se passaram desde a última interação (neste caso, o último login) do usuário até a data de hoje.\n",
    "    - Interpreção: Um valor baixo indica que o usuário fez login recentemente e está engajado.Um valor alto indica que o usuário está inativo ou pode estar em risco de churn (abandono).\n",
    "    uso: \n",
    "    ```python\n",
    "    df['recency'] = (pd.Timestamp(\"2025-10-01\") - df['last_login']).dt.days # exemplo com data fixa\n",
    "    ```\n",
    "    <br><br>\n",
    "    > account_age_days = (today - signup_date).days.\n",
    "    - Conceito: Mede a idade total da conta do usuário em dias, desde a data de cadastro (signup_date) até hoje.\n",
    "    - Interpretação: Um valor alto indica que o usuário é um cliente antigo, o que pode sugerir lealdade. Um valor baixo indica um cliente novo, que pode estar em fase de avaliação do serviço.\n",
    "    uso: \n",
    "    ```python\n",
    "    df['account_age_days'] = (pd.Timestamp(\"2025-10-01\") - df['signup_date']).dt.days # exemplo com data fixa\n",
    "    ```\n",
    "    <br><br>\n",
    "    > activity_rate = num_transactions / max(1, account_age_days/30).\n",
    "    - Conceito: Mede a frequência média de transações do usuário por mês, normalizando pelo tempo que a conta está ativa.\n",
    "    - Detalhes da fórmula:\n",
    "        - num_transactions: O número total de transações feitas pelo usuário.\n",
    "        - account_age_days/30: Converte a idade da conta em dias para a idade da conta em meses.\n",
    "        max(1, ...): É uma técnica de proteção contra divisão por zero ou por um período de tempo muito pequeno. Garante que o denominador seja pelo menos 1, o que é crucial para contas criadas há menos de um mês (para evitar uma taxa de atividade inflacionada ou divisão por zero).\n",
    "    - Interpretação: Um valor alto indica um usuário ativo que realiza transações regularmente. Um valor baixo pode indicar um usuário inativo ou com baixo engajamento.\n",
    "    uso: \n",
    "    ```python\n",
    "    # Calcula a idade em meses, garantindo que o divisor seja no mínimo 1\n",
    "    age_months = df_usuarios['account_age_days'] / 30\n",
    "    divisor = np.maximum(1, age_months)\n",
    "\n",
    "    df_usuarios['activity_rate'] = df_usuarios['num_transactions'] / divisor\n",
    "    ```\n",
    "\n",
    "4. Tratamento de missing\n",
    "    > income: imputar com median + flag is_income_missing.\n",
    "    - imputação:\n",
    "        - \n",
    "    > last_login: imputar com signup_date (ou grande recency) + flag.\n",
    "    > review_text: preencher \"\" + flag.\n",
    "\n",
    "5. Outliers\n",
    "    - truncamento (winsorize) ou log-transform para income e avg_transaction; criar versão transformada.\n",
    "6. Encoding\n",
    "    - categóricas: One-Hot para device/product; target/mean-encoding ou frequency-encoding para country (avaliar leakage).\n",
    "    - texto: TF-IDF (unigram/bigram) limitando vocab (top k) ou usar hash vectorizer.\n",
    "7. Pipeline e seleção\n",
    "    - montar sklearn ColumnTransformer + Pipeline (imputer, scaler, encoders, text vect).\n",
    "    - reduzir dimensionalidade texto com TruncatedSVD se usar TF-IDF.\n",
    "8. Validação e modelagem\n",
    "    - split temporal: usar cutoff por signup_date (treino até T, teste após T) ou holdout estratificado respeitando tempo.\n",
    "    - baseline model: LogisticRegression (class_weight='balanced') e/ou XGBoost.\n",
    "    - métricas: ROC AUC, Precision@k (ex.: top 10%), e matriz de confusão; reportar recall/precision para classe positiva.\n",
    "9. Interpretabilidade\n",
    "    - features mais importantes (coeficientes ou SHAP).\n",
    "    - avaliar ganho por tipo de feature (numéricas vs texto vs categóricas).\n",
    "\n",
    "Entregáveis esperados:\n",
    "\n",
    "- Notebook (feature_engineering2.ipynb) com código organizado, células comentadas e resultados (gráficos/tabelas).\n",
    "- Modelo salvo (pickle) e arquivo com feature importances.\n",
    "- Breve relatório (markdown no notebook) com:\n",
    "    - resumo das transformações,\n",
    "    - métricas finais no conjunto teste,\n",
    "    - duas recomendações de próximas melhorias.\n",
    "\n",
    "Critério mínimo de aceitação:\n",
    "\n",
    "- Pipeline reproduzível (pode rodar a célula final e gerar métricas).\n",
    "- ROC AUC >= 0.70 ou explicação curta se não atingir (p.ex., sinal fraco).\n",
    "- Documentação das decisões de imputação e tratamento de outliers.\n",
    "\n",
    "Dicas rápidas de implementação:\n",
    "\n",
    "- use sklearn.compose.ColumnTransformer, sklearn.pipeline.Pipeline.\n",
    "- para texto: sklearn.feature_extraction.text.TfidfVectorizer + TruncatedSVD.\n",
    "- para avaliação temporal: sort by signup_date e use TimeSeriesSplit ou cutoff manual.\n",
    "- fixe \"today\" com uma data constante (ex.: pd.Timestamp(\"2025-10-01\")) para reprodutibilidade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731dd0b6-decb-44b8-a72b-c69040a2af50",
   "metadata": {},
   "source": [
    "- o pandas é para manipulação de dados\n",
    "- a numpy é para trabalharmos com algumas operações matematicas\n",
    "- o dataframe serve para organizar e manipular dados tabulares, como planilhas ou tabelas de banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "511dce96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas com sucesso. <module 'numpy' from 'c:\\\\Users\\\\joaop\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\numpy\\\\__init__.py'> <module 'pandas' from 'c:\\\\Users\\\\joaop\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\pandas\\\\__init__.py'> <class 'pandas.core.frame.DataFrame'> <module 'seaborn' from 'c:\\\\Users\\\\joaop\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\seaborn\\\\__init__.py'> <module 'matplotlib.pyplot' from 'c:\\\\Users\\\\joaop\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\matplotlib\\\\pyplot.py'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # utilização do pandas para manipulação de dados\n",
    "import numpy as np # utilização do numpy para operações numéricas\n",
    "from pandas import DataFrame # importação específica do DataFrame do pandas\n",
    "import seaborn as sns # utilização do seaborn para visualização de dados\n",
    "import matplotlib.pyplot as plt # utilização do matplotlib para criação de gráficos\n",
    "print(\"Bibliotecas importadas com sucesso.\", np, pd, DataFrame, sns, plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef6aef75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>attributed_time</th>\n",
       "      <th>is_attributed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89489</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 15:13:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204158</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>2017-11-06 15:41:07</td>\n",
       "      <td>2017-11-07 08:17:19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3437</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>459</td>\n",
       "      <td>2017-11-06 15:42:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>167543</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 15:56:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>147509</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 15:57:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel           click_time      attributed_time  \\\n",
       "0   89489    3       1  13      379  2017-11-06 15:13:23                  NaN   \n",
       "1  204158   35       1  13       21  2017-11-06 15:41:07  2017-11-07 08:17:19   \n",
       "2    3437    6       1  13      459  2017-11-06 15:42:32                  NaN   \n",
       "3  167543    3       1  13      379  2017-11-06 15:56:17                  NaN   \n",
       "4  147509    3       1  13      379  2017-11-06 15:57:01                  NaN   \n",
       "\n",
       "   is_attributed  \n",
       "0              0  \n",
       "1              1  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"datasets/train_sample.csv\")\n",
    "data.head() # Display the first few rows of the dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
